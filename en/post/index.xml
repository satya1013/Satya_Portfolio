<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Satya Kumari</title>
    <link>https://satya1013.github.io/satya_portfolio/en/post/</link>
    <description>Recent content in Projects on Satya Kumari</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 Mar 2017 12:00:00 -0500</lastBuildDate><atom:link href="https://satya1013.github.io/satya_portfolio/en/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Project IV: Fake News Detection</title>
      <link>https://satya1013.github.io/satya_portfolio/en/post/project-4/</link>
      <pubDate>Sun, 12 Dec 2021 11:14:48 -0400</pubDate>
      
      <guid>https://satya1013.github.io/satya_portfolio/en/post/project-4/</guid>
      <description>The purpose of this project is to conduct analysis on certain textual data which is extracted from various articles and conclude the judgement of whether the data is fake or real, with the goal of mitgating the spread of fake news. The dataset is downloaded from kaggle which is used in a fake-news-detectin competition. it contains extraxts of various articles and their label of real or not. The first experiment with recurrent neural network gives accuracy around 0.</description>
    </item>
    
    <item>
      <title>Project III: Image segmentation using UNet</title>
      <link>https://satya1013.github.io/satya_portfolio/en/post/project-3/</link>
      <pubDate>Sun, 11 Apr 2021 11:13:32 -0400</pubDate>
      
      <guid>https://satya1013.github.io/satya_portfolio/en/post/project-3/</guid>
      <description>Image segmentation is a process of breaking down image in various subgroups by cassifying each pixel in a perticular segement.
  UNet model was first used for biomedical image segmenatation, the UNet archiecture is especially good for segmentation.
  Model implmentation was done with the help of keras and tensorflow.
  Binary crossentropy was used as a loss function and ADAM as the optimizer.
  The model was evaluated with mean Dice coefficient and achieved upto 93% score.</description>
    </item>
    
    <item>
      <title>Project II: Spam Classifier</title>
      <link>https://satya1013.github.io/satya_portfolio/en/post/project-2/</link>
      <pubDate>Thu, 10 Dec 2020 11:00:59 -0400</pubDate>
      
      <guid>https://satya1013.github.io/satya_portfolio/en/post/project-2/</guid>
      <description>dataset contains various messages which is to be classified as spam or not. pile of texts converted into vectors considering their term frequncy and inverse document frequency. Naive Bayed clssifier is used as final model.   Word cloud   Link to Github Repository</description>
    </item>
    
    <item>
      <title>project I: Spotfy Data Analysis</title>
      <link>https://satya1013.github.io/satya_portfolio/en/post/project-1/</link>
      <pubDate>Wed, 09 Sep 2020 10:58:08 -0400</pubDate>
      
      <guid>https://satya1013.github.io/satya_portfolio/en/post/project-1/</guid>
      <description>Statistical techniques and visualization were considered for better understanding of data. Time-series Analysis using Python, NumPy, Seaborn,Matplotlib. Trained unsupervised model to differentiate super-Genre. trained supervised model to predict popularity of the songs.   Graph from project   Link to Github Repository</description>
    </item>
    
  </channel>
</rss>
